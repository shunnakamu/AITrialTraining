{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "make_summary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGzS6tJ41QXcGlwGL5N1pW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d0650cf0cf8494f8cb86b1a615c46d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0beccd86c65047e0a64350ea9dbdc0f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad5407c84f4144539ca2775e62346b00",
              "IPY_MODEL_273f851b1041439b9102c7ae1729f217"
            ]
          }
        },
        "0beccd86c65047e0a64350ea9dbdc0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad5407c84f4144539ca2775e62346b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c94a2f29435c4af9910ec0f1a5dcfcef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_983c31070a00468d9e842cc81d6cace0"
          }
        },
        "273f851b1041439b9102c7ae1729f217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a431376718ad4a3a9dad202aab1a1024",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00, 11.16 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0027f7c5f2834ad7bb3a4b77cfdc75b5"
          }
        },
        "c94a2f29435c4af9910ec0f1a5dcfcef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "983c31070a00468d9e842cc81d6cace0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a431376718ad4a3a9dad202aab1a1024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0027f7c5f2834ad7bb3a4b77cfdc75b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8b23de343d640b8a05e3c8e4bc00406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83d163ba898c4dc78f9efcdce1b55613",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_652ce8e80bcd4072b599f458d23f75bf",
              "IPY_MODEL_00d7671b30d2420d92f9987d6e9fee67"
            ]
          }
        },
        "83d163ba898c4dc78f9efcdce1b55613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "652ce8e80bcd4072b599f458d23f75bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c137065b8eaf410db0400fe89f4187e1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d435a36a12845ddbe8a08023bd86a7b"
          }
        },
        "00d7671b30d2420d92f9987d6e9fee67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99c4a2ff03b1456ea172f741ceeafb79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [04:30&lt;00:00, 54.01s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15cd605d4d9f4df0b80248d98a680378"
          }
        },
        "c137065b8eaf410db0400fe89f4187e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d435a36a12845ddbe8a08023bd86a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99c4a2ff03b1456ea172f741ceeafb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15cd605d4d9f4df0b80248d98a680378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsubauaaa/AITrialTraining/blob/main/Training4/make_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEvi8gKZ51qO",
        "outputId": "0bb1e7ec-f034-44e3-8575-71261dbd40e4"
      },
      "source": [
        " # Google Driveをマウントする\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1UjH2W6yge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449957d8-f672-4f4d-9d3d-bbf0a2016248"
      },
      "source": [
        "!pip install -U pip\n",
        "!pip install transformers\n",
        "!pip install -r \"/content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt\""
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: datasets>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 2)) (0.1.95)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 5)) (0.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (0.70.11.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (0.8.7)\n",
            "Requirement already satisfied: huggingface-hub==0.0.2 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (0.0.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 3)) (54.0.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/My Drive/Colab Notebooks/AITraining/transformers-examples/requirements.txt (line 1)) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE9J2zRLJId_"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from datasets import load_dataset, load_metric\n",
        "from filelock import FileLock\n",
        "from typing import Optional\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    HfArgumentParser,\n",
        "    MBartTokenizer,\n",
        "    MBartTokenizerFast,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    default_data_collator,\n",
        "    set_seed,\n",
        ")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoxlH1ObT_Ai"
      },
      "source": [
        "with FileLock(\".lock\") as lock:\n",
        "    nltk.download(\"punkt\", quiet=True)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yFLWCYNHNMi"
      },
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: str = field(\n",
        "        metadata={\n",
        "            \"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"\n",
        "        }\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Pretrained config name or path if not the same as model_name\"\n",
        "        },\n",
        "    )\n",
        "    tokenizer_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Pretrained tokenizer name or path if not the same as model_name\"\n",
        "        },\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Where to store the pretrained models downloaded from huggingface.co\"\n",
        "        },\n",
        "    )\n",
        "    use_fast_tokenizer: bool = field(\n",
        "        default=True,\n",
        "        metadata={\n",
        "            \"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"\n",
        "        },\n",
        "    )\n",
        "    model_revision: str = field(\n",
        "        default=\"main\",\n",
        "        metadata={\n",
        "            \"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"\n",
        "        },\n",
        "    )\n",
        "    use_auth_token: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
        "            \"with private models).\"\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    task: str = field(\n",
        "        default=\"summarization\",\n",
        "        metadata={\n",
        "            \"help\": \"The name of the task, should be summarization (or summarization_{dataset} for evaluating \"\n",
        "            \"pegasus) or translation (or translation_{xx}_to_{yy}).\"\n",
        "        },\n",
        "    )\n",
        "    dataset_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"},\n",
        "    )\n",
        "    dataset_config_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"The configuration name of the dataset to use (via the datasets library).\"\n",
        "        },\n",
        "    )\n",
        "    text_column: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"The name of the column in the datasets containing the full texts (for summarization).\"\n",
        "        },\n",
        "    )\n",
        "    summary_column: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"The name of the column in the datasets containing the summaries (for summarization).\"\n",
        "        },\n",
        "    )\n",
        "    train_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The input training data file (a jsonlines or csv file).\"},\n",
        "    )\n",
        "    validation_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"An optional input evaluation data file to evaluate the metrics (rouge/sacreblue) on \"\n",
        "            \"(a jsonlines or csv file).\"\n",
        "        },\n",
        "    )\n",
        "    test_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"An optional input test data file to evaluate the metrics (rouge/sacreblue) on \"\n",
        "            \"(a jsonlines or csv file).\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Overwrite the cached training and evaluation sets\"},\n",
        "    )\n",
        "    preprocessing_num_workers: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
        "    )\n",
        "    max_source_length: Optional[int] = field(\n",
        "        default=1024,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    max_target_length: Optional[int] = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total sequence length for target text after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    val_max_target_length: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total sequence length for validation target text after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded. Will default to `max_target_length`.\"\n",
        "            \"This argument is also used to override the ``max_length`` param of ``model.generate``, which is used \"\n",
        "            \"during ``evaluate`` and ``predict``.\"\n",
        "        },\n",
        "    )\n",
        "    pad_to_max_length: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": \"Whether to pad all samples to model maximum sentence length. \"\n",
        "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n",
        "            \"efficient on GPU but very bad for TPU.\"\n",
        "        },\n",
        "    )\n",
        "    max_train_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
        "            \"value if set.\"\n",
        "        },\n",
        "    )\n",
        "    max_val_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"For debugging purposes or quicker training, truncate the number of validation examples to this \"\n",
        "            \"value if set.\"\n",
        "        },\n",
        "    )\n",
        "    max_test_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"For debugging purposes or quicker training, truncate the number of test examples to this \"\n",
        "            \"value if set.\"\n",
        "        },\n",
        "    )\n",
        "    source_lang: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Source language id for translation.\"}\n",
        "    )\n",
        "    target_lang: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Target language id for translation.\"}\n",
        "    )\n",
        "    num_beams: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Number of beams to use for evaluation. This argument will be passed to ``model.generate``, \"\n",
        "            \"which is used during ``evaluate`` and ``predict``.\"\n",
        "        },\n",
        "    )\n",
        "    ignore_pad_token_for_loss: bool = field(\n",
        "        default=True,\n",
        "        metadata={\n",
        "            \"help\": \"Whether to ignore the tokens corresponding to padded labels in the loss computation or not.\"\n",
        "        },\n",
        "    )\n",
        "    source_prefix: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"A prefix to add before every source text (useful for T5 models).\"\n",
        "        },\n",
        "    )\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if (\n",
        "            self.dataset_name is None\n",
        "            and self.train_file is None\n",
        "            and self.validation_file is None\n",
        "        ):\n",
        "            pass\n",
        "        #             raise ValueError(\"Need either a dataset name or a training/validation file.\")\n",
        "        else:\n",
        "            if self.train_file is not None:\n",
        "                extension = self.train_file.split(\".\")[-1]\n",
        "                assert extension in [\n",
        "                    \"csv\",\n",
        "                    \"json\",\n",
        "                ], \"`train_file` should be a csv or a json file.\"\n",
        "            if self.validation_file is not None:\n",
        "                extension = self.validation_file.split(\".\")[-1]\n",
        "                assert extension in [\n",
        "                    \"csv\",\n",
        "                    \"json\",\n",
        "                ], \"`validation_file` should be a csv or a json file.\"\n",
        "        if not self.task.startswith(\"summarization\") and not self.task.startswith(\n",
        "            \"translation\"\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                \"`task` should be summarization, summarization_{dataset}, translation or translation_{xx}_to_{yy}.\"\n",
        "            )\n",
        "        if self.val_max_target_length is None:\n",
        "            self.val_max_target_length = self.max_target_length\n",
        "\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbEn7zN0GtVm"
      },
      "source": [
        "parser = HfArgumentParser(\n",
        "    (ModelArguments, DataTrainingArguments, Seq2SeqTrainingArguments)\n",
        ")\n",
        "model_args, data_args, training_args = parser.parse_json_file(\n",
        "    json_file=os.path.abspath(\"/content/drive/My Drive/Colab Notebooks/AITraining/config.json\")\n",
        ")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "1d0650cf0cf8494f8cb86b1a615c46d3",
            "0beccd86c65047e0a64350ea9dbdc0f6",
            "ad5407c84f4144539ca2775e62346b00",
            "273f851b1041439b9102c7ae1729f217",
            "c94a2f29435c4af9910ec0f1a5dcfcef",
            "983c31070a00468d9e842cc81d6cace0",
            "a431376718ad4a3a9dad202aab1a1024",
            "0027f7c5f2834ad7bb3a4b77cfdc75b5"
          ]
        },
        "id": "lzpVrGDyQpjS",
        "outputId": "73433363-d799-4aef-c116-03a0629e05fd"
      },
      "source": [
        "data_files = {}\n",
        "data_files[\"test\"] = data_args.test_file\n",
        "extension = data_args.test_file.split(\".\")[-1]\n",
        "datasets = load_dataset(extension, data_files=data_files)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-34787d3084171da5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-34787d3084171da5/0.0.0/dc7ee63ec8b554c48ecc5a8a6fbe27af8071408c244e4347cf9222d6206d83a2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d0650cf0cf8494f8cb86b1a615c46d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-34787d3084171da5/0.0.0/dc7ee63ec8b554c48ecc5a8a6fbe27af8071408c244e4347cf9222d6206d83a2. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd4bZkfsKIMw"
      },
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    model_args.config_name\n",
        "    if model_args.config_name\n",
        "    else model_args.model_name_or_path,\n",
        "    cache_dir=model_args.cache_dir,\n",
        "    revision=model_args.model_revision,\n",
        "    use_auth_token=True if model_args.use_auth_token else None,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_args.tokenizer_name\n",
        "    if model_args.tokenizer_name\n",
        "    else model_args.model_name_or_path,\n",
        "    cache_dir=model_args.cache_dir,\n",
        "    use_fast=model_args.use_fast_tokenizer,\n",
        "    revision=model_args.model_revision,\n",
        "    use_auth_token=True if model_args.use_auth_token else None,\n",
        ")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_args.model_name_or_path,\n",
        "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
        "    config=config,\n",
        "    cache_dir=model_args.cache_dir,\n",
        "    revision=model_args.model_revision,\n",
        "    use_auth_token=True if model_args.use_auth_token else None,\n",
        ")"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHGL5ClEI3r9"
      },
      "source": [
        "prefix = data_args.source_prefix if data_args.source_prefix is not None else \"\"\n",
        "column_names = datasets[\"test\"].column_names"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKyvLGDiJEUA"
      },
      "source": [
        "summarization_name_mapping = {\n",
        "    \"amazon_reviews_multi\": (\"review_body\", \"review_title\"),\n",
        "    \"big_patent\": (\"description\", \"abstract\"),\n",
        "    \"cnn_dailymail\": (\"article\", \"highlights\"),\n",
        "    \"orange_sum\": (\"text\", \"summary\"),\n",
        "    \"pn_summary\": (\"article\", \"summary\"),\n",
        "    \"psc\": (\"extract_text\", \"summary_text\"),\n",
        "    \"samsum\": (\"dialogue\", \"summary\"),\n",
        "    \"thaisum\": (\"body\", \"summary\"),\n",
        "    \"xglue\": (\"news_body\", \"news_title\"),\n",
        "    \"xsum\": (\"document\", \"summary\"),\n",
        "    \"wiki_summary\": (\"article\", \"highlights\"),\n",
        "}\n",
        "\n",
        "source_lang, target_lang, text_column, summary_column = None, None, None, None\n",
        "\n",
        "# Get the column names for input/target.\n",
        "dataset_columns = summarization_name_mapping.get(data_args.dataset_name, None)\n",
        "if data_args.text_column is None:\n",
        "    text_column = (\n",
        "        dataset_columns[0] if dataset_columns is not None else column_names[0]\n",
        "    )\n",
        "else:\n",
        "    text_column = data_args.text_column\n",
        "if data_args.summary_column is None:\n",
        "    summary_column = (\n",
        "        dataset_columns[1] if dataset_columns is not None else column_names[1]\n",
        "    )\n",
        "else:\n",
        "    summary_column = data_args.summary_column\n",
        "\n",
        "max_target_length = data_args.max_target_length\n",
        "padding = \"max_length\" if data_args.pad_to_max_length else False"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O19qittjN6zL"
      },
      "source": [
        "def preprocess_function(examples):\n",
        "    if data_args.task.startswith(\"translation\"):\n",
        "        inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
        "        targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "    else:\n",
        "        inputs = examples[text_column]\n",
        "        targets = examples[summary_column]\n",
        "    inputs = [prefix + inp for inp in inputs]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=data_args.max_source_length,\n",
        "        padding=padding,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets, max_length=max_target_length, padding=padding, truncation=True\n",
        "        )\n",
        "\n",
        "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
        "    # padding in the loss.\n",
        "    if padding == \"max_length\" and data_args.ignore_pad_token_for_loss:\n",
        "        labels[\"input_ids\"] = [\n",
        "            [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
        "            for label in labels[\"input_ids\"]\n",
        "        ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e8b23de343d640b8a05e3c8e4bc00406",
            "83d163ba898c4dc78f9efcdce1b55613",
            "652ce8e80bcd4072b599f458d23f75bf",
            "00d7671b30d2420d92f9987d6e9fee67",
            "c137065b8eaf410db0400fe89f4187e1",
            "8d435a36a12845ddbe8a08023bd86a7b",
            "99c4a2ff03b1456ea172f741ceeafb79",
            "15cd605d4d9f4df0b80248d98a680378"
          ]
        },
        "id": "-5steRbaHtTH",
        "outputId": "67b780f6-5079-41e7-a56e-727307131c06"
      },
      "source": [
        "max_target_length = data_args.val_max_target_length\n",
        "if \"test\" not in datasets:\n",
        "    raise ValueError(\"--do_predict requires a test dataset\")\n",
        "test_dataset = datasets[\"test\"]\n",
        "if data_args.max_test_samples is not None:\n",
        "    test_dataset = test_dataset.select(range(data_args.max_test_samples))\n",
        "test_dataset = test_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=data_args.preprocessing_num_workers,\n",
        "    remove_columns=column_names,\n",
        "    load_from_cache_file=not data_args.overwrite_cache,\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "label_pad_token_id = (\n",
        "    -100 if data_args.ignore_pad_token_for_loss else tokenizer.pad_token_id\n",
        ")\n",
        "if data_args.pad_to_max_length:\n",
        "    data_collator = default_data_collator\n",
        "else:\n",
        "    data_collator = DataCollatorForSeq2Seq(\n",
        "        tokenizer,\n",
        "        model=model,\n",
        "        label_pad_token_id=label_pad_token_id,\n",
        "        pad_to_multiple_of=8 if training_args.fp16 else None,\n",
        "    )\n",
        "\n",
        "# Metric\n",
        "metric_name = \"rouge\" if data_args.task.startswith(\"summarization\") else \"sacrebleu\"\n",
        "metric = load_metric(metric_name)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8b23de343d640b8a05e3c8e4bc00406",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCHjDtQWS7IA"
      },
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    if metric_name == \"rouge\":\n",
        "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "    else:  # sacrebleu\n",
        "        labels = [[label] for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_kqwgFTSjlu"
      },
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    if data_args.ignore_pad_token_for_loss:\n",
        "        # Replace -100 in the labels as we can't decode them.\n",
        "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    if metric_name == \"rouge\":\n",
        "        result = metric.compute(\n",
        "            predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "        )\n",
        "        # Extract a few results from ROUGE\n",
        "        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    else:\n",
        "        result = metric.compute(\n",
        "            predictions=decoded_preds, references=decoded_labels\n",
        "        )\n",
        "        result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFE_DoZ8e1T1"
      },
      "source": [
        "# Initialize our Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset if training_args.do_train else None,\n",
        "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        "    if training_args.predict_with_generate\n",
        "    else None,\n",
        ")"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "kaVl5ItIJ33n",
        "outputId": "b01be915-e2a7-455f-ae2a-fb2dd9f3be02"
      },
      "source": [
        "test_results = trainer.predict(\n",
        "    test_dataset,\n",
        "    metric_key_prefix=\"test\",\n",
        "    max_length=data_args.val_max_target_length,\n",
        "    num_beams=data_args.num_beams,\n",
        ")\n",
        "metrics = test_results.metrics\n",
        "max_test_samples = (\n",
        "    data_args.max_test_samples\n",
        "    if data_args.max_test_samples is not None\n",
        "    else len(test_dataset)\n",
        ")\n",
        "metrics[\"test_samples\"] = min(max_test_samples, len(test_dataset))\n",
        "\n",
        "if trainer.is_world_process_zero():\n",
        "    if training_args.predict_with_generate:\n",
        "        test_preds = tokenizer.batch_decode(\n",
        "            test_results.predictions,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=True,\n",
        "        )\n",
        "        test_preds = [pred.strip() for pred in test_preds]\n",
        "        output_test_preds_file = os.path.join(\n",
        "            training_args.output_dir, \"test_preds_seq2seq.txt\"\n",
        "        )\n",
        "        # test_predsは要約リスト\n",
        "        # print(test_preds)\n",
        "        with open(output_test_preds_file, \"w\") as writer:\n",
        "            writer.write(\"\\n\".join(test_preds))\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 1:36:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwIfDUXAPBUr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}