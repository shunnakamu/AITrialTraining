{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AITraining3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJosq7RgS73cV4eaTx4PRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsubauaaa/AITrialTraining/blob/main/Training3/AITraining3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEvi8gKZ51qO",
        "outputId": "f9b8013a-171b-42a0-a642-d646a0f1699e"
      },
      "source": [
        " # Google Driveをマウントする\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_0hFdJwXF7w",
        "outputId": "1ce455ce-2297-4fc7-d1e5-470d0b0b9d07"
      },
      "source": [
        "# install MeCab\n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null\n",
        "# check path to \"ipadic-neologd\"\n",
        "!echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"\n",
        "\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mecab-ipadic-neologd' already exists and is not an empty directory.\n",
            "/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "ln: failed to create symbolic link '/usr/local/etc/mecabrc': File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1VKEi7usaW2"
      },
      "source": [
        "import json\n",
        "import gensim\n",
        "import MeCab\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOnsQQhr5pky"
      },
      "source": [
        "decoder = json.JSONDecoder()\n",
        "all_datasets_list = []\n",
        "with open('/content/drive/My Drive/Colab Notebooks/AITraining/dataset_ja_dev.json') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        all_datasets_list.append(decoder.raw_decode(line)[0])\n",
        "        line = f.readline()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFfnpT1G6rpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f09bf98-9ff5-4576-93e0-b9180454c241"
      },
      "source": [
        "all_datasets_list[1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'ja',\n",
              " 'product_category': 'wireless',\n",
              " 'product_id': 'product_ja_0821731',\n",
              " 'review_body': 'ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。',\n",
              " 'review_id': 'ja_0944897',\n",
              " 'review_title': '欠陥品',\n",
              " 'reviewer_id': 'reviewer_ja_0192786',\n",
              " 'stars': '1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "04UlblNH7dBK",
        "outputId": "dea8a25e-9d30-4462-9ad5-846b101166f0"
      },
      "source": [
        "datasets_list = []\n",
        "for data in all_datasets_list:\n",
        "    review_body = data['review_body']\n",
        "    stars = data['stars']\n",
        "    datasets_list.append([review_body, stars])\n",
        "datasets = pd.DataFrame(datasets_list, columns = ['review_body' , 'stars'])\n",
        "datasets"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>新旧含めて4つのカーテンレールがあるのですが、使用出来るカーテンレールはありませんでした。 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>予約注文でしたが、どこから特典であるpdfダウンロードすればよいのでしょうか…</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>前のレビューにもありましたが、片方が全く動きません。 返品しようにも、なんだかめんどくさいし...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>ミニオンが好きで、息子に買いました。 親子で楽しく遊んでます。</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>まずレーザーの光が強いw 昔 ゲーセンで取ったヤツの3倍くらい 暗闇でレーザーの光が当たった...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>色もち、発色もよく、ティントによくある\"激しい唇の荒れ\"が少ないのでとても使いやすいなと思い...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1年前に別メーカーのバッテリーを交換して、使えましたが、スマホ確認のところで認識さらませんで...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>前なら剃った次の日はまた、ポツポツでそれを抜いてましたがポツポツがありません！</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            review_body stars\n",
              "0     味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込...     1\n",
              "1                ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。     1\n",
              "2     新旧含めて4つのカーテンレールがあるのですが、使用出来るカーテンレールはありませんでした。 ...     1\n",
              "3               予約注文でしたが、どこから特典であるpdfダウンロードすればよいのでしょうか…     1\n",
              "4     前のレビューにもありましたが、片方が全く動きません。 返品しようにも、なんだかめんどくさいし...     1\n",
              "...                                                 ...   ...\n",
              "4995                    ミニオンが好きで、息子に買いました。 親子で楽しく遊んでます。     5\n",
              "4996  まずレーザーの光が強いw 昔 ゲーセンで取ったヤツの3倍くらい 暗闇でレーザーの光が当たった...     5\n",
              "4997  色もち、発色もよく、ティントによくある\"激しい唇の荒れ\"が少ないのでとても使いやすいなと思い...     5\n",
              "4998  1年前に別メーカーのバッテリーを交換して、使えましたが、スマホ確認のところで認識さらませんで...     5\n",
              "4999            前なら剃った次の日はまた、ポツポツでそれを抜いてましたがポツポツがありません！     5\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1UjH2W6yge"
      },
      "source": [
        "tagger = MeCab.Tagger(\"-Owakati\")\n",
        "# param: dataset_list[]['review_body']\n",
        "# return: 分かちした単語のリスト\n",
        "def make_wakati(sentence):\n",
        "    # MeCabで分かち書き\n",
        "    sentence = tagger.parse(sentence)\n",
        "    # 半角全角英数字除去\n",
        "    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
        "    # 記号もろもろ除去\n",
        "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
        "    # スペースで区切って形態素の配列へ\n",
        "    wakati = sentence.split(\" \")\n",
        "    # 空の要素は削除\n",
        "    wakati = list(filter((\"\").__ne__, wakati))\n",
        "    return wakati"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAOqxOpxhe6s",
        "outputId": "05f2e5e0-40df-47e8-8178-e80e88a1a347"
      },
      "source": [
        "# w2vする\n",
        "w2v_model = gensim.models.Word2Vec.load('/content/drive/My Drive/Colab Notebooks/AITraining/w2v/w2v.model')\n",
        "word2vec = {}\n",
        "no_words = []\n",
        "for dataset in datasets_list:\n",
        "    wakati = make_wakati(dataset[0])\n",
        "    for word in wakati:\n",
        "        if word in word2vec:\n",
        "            continue\n",
        "        if word not in list(w2v_model.wv.vocab):\n",
        "            no_words.append(word)\n",
        "            continue\n",
        "        word2vec[word] = w2v_model.wv[word]\n",
        "print(len(word2vec))\n",
        "print(len(no_words))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12739\n",
            "711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Q4mAMD1xHs"
      },
      "source": [
        "# 単語をベクトルデータに変換\n",
        "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
        "def sentence2vec(sentence):\n",
        "    wakati = make_wakati(sentence)\n",
        "    return torch.tensor([word2vec[w] for w in wakati])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egd-cKlV12PD"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
        "class LSTMRegressor(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "    def __init__(self, embedding_dim, hidden_dim):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMRegressor, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "    def forward(self, sentence):\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        _, lstm_out = self.lstm(sentence)\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        output = self.out(lstm_out[0].view(-1, self.hidden_dim))\n",
        "        return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ_DZmzN2Lac",
        "outputId": "211f8257-ca43-4a7d-958e-2e7984902026"
      },
      "source": [
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 128\n",
        "lstm = LSTMRegressor(EMBEDDING_DIM, HIDDEN_DIM)\n",
        "s1 = datasets_list[0][0]\n",
        "s2 = datasets_list[0][1]\n",
        "print(s1)\n",
        "# 味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込み も出来なかった。腹が立ってごみ箱行きでした。こんなものは２度と購入する気はない。 返品するのも交渉するのも、金額も金額だからと面倒くさがってしない方が多いのではないか？ 最初から不良品多しとでも表記しておいたら如何？\n",
        "print(make_wakati(s1))\n",
        "# ['味', '自体', '及び', '吸い', '心地', 'は', '良い', 'の', 'だ', 'が', '不', '良品', 'が', '多', '過ぎる', '私', 'の', '場合', '本', 'の', 'うち', '本', 'が', '蒸気', 'も', '出', 'ず', '吸い込み', 'も', '出来', 'なかっ', 'た', '腹', 'が', '立っ', 'て', 'ごみ箱', '行き', 'でし', 'た', 'こんな', 'もの', 'は', '度', 'と', '購入', 'する', '気', 'は', 'ない', '返品', 'する', 'の', 'も', '交渉', 'する', 'の', 'も', '金額', 'も', '金額', 'だ', 'から', 'と', '面倒く', 'さ', 'がっ', 'て', 'し', 'ない', '方', 'が', '多い', 'の', 'で', 'は', 'ない', 'か', '最初', 'から', '不', '良品', '多し', 'と', 'でも', '表記', 'し', 'て', 'おい', 'たら', '如何']\n",
        "\n",
        "inputs1 = sentence2vec(s1)\n",
        "print(inputs1)\n",
        "out = lstm(inputs1.view(len(inputs1), 1, -1))\n",
        "print(out)\n",
        "print(s2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込み も出来なかった。腹が立ってごみ箱行きでした。こんなものは２度と購入する気はない。 返品するのも交渉するのも、金額も金額だからと面倒くさがってしない方が多いのではないか？ 最初から不良品多しとでも表記しておいたら如何？\n",
            "['味', '自体', '及び', '吸い', '心地', 'は', '良い', 'の', 'だ', 'が', '不', '良品', 'が', '多', '過ぎる', '私', 'の', '場合', '本', 'の', 'うち', '本', 'が', '蒸気', 'も', '出', 'ず', '吸い込み', 'も', '出来', 'なかっ', 'た', '腹', 'が', '立っ', 'て', 'ごみ箱', '行き', 'でし', 'た', 'こんな', 'もの', 'は', '度', 'と', '購入', 'する', '気', 'は', 'ない', '返品', 'する', 'の', 'も', '交渉', 'する', 'の', 'も', '金額', 'も', '金額', 'だ', 'から', 'と', '面倒く', 'さ', 'がっ', 'て', 'し', 'ない', '方', 'が', '多い', 'の', 'で', 'は', 'ない', 'か', '最初', 'から', '不', '良品', '多し', 'と', 'でも', '表記', 'し', 'て', 'おい', 'たら', '如何']\n",
            "tensor([[-0.4999, -0.6908, -2.5520,  ...,  1.2527, -0.7275,  0.6183],\n",
            "        [ 0.3367,  0.8707, -0.7007,  ...,  0.4871,  0.3114, -0.0030],\n",
            "        [ 1.1938, -0.3116,  0.3566,  ...,  2.1716,  1.3614, -1.0291],\n",
            "        ...,\n",
            "        [-0.6864, -1.0068,  1.2038,  ..., -1.4014, -1.4441,  1.2285],\n",
            "        [-0.6333, -2.3974, -0.3745,  ..., -1.2556, -2.5141, -1.6721],\n",
            "        [-0.1302,  0.5549,  0.0820,  ..., -1.7729, -0.4356,  0.1791]])\n",
            "tensor([[0.0772]], grad_fn=<AddmmBackward>)\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv1lVDDt38wy",
        "outputId": "baba9f9e-e777-4a05-87eb-3c8dfd7c0e50"
      },
      "source": [
        "len_datasets = len(datasets_list)\n",
        "# starsをtensorにする\n",
        "category2index = {}\n",
        "for i in range(len_datasets):\n",
        "    star = datasets_list[i][1]\n",
        "    if star in category2index: continue\n",
        "    category2index[star] = len(category2index)\n",
        "print(category2index)\n",
        "\n",
        "def category2tensor(star):\n",
        "    return torch.tensor([category2index[star]], dtype=torch.float)\n",
        "\n",
        "print(category2tensor(\"2\"))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
            "tensor([1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsoIFDE06TFP",
        "outputId": "f9bb6e5e-34b3-4c76-82e0-136552068132"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "# 元データを7:3に分ける（7->学習、3->テスト）\n",
        "traindata, testdata = train_test_split(datasets, train_size=0.7, shuffle=True)\n",
        "# 単語のベクトル次元数\n",
        "EMBEDDING_DIM = 200\n",
        "# 隠れ層の次元数\n",
        "HIDDEN_DIM = 128\n",
        "# モデル宣言\n",
        "model = LSTMRegressor(EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
        "loss_function = nn.MSELoss()\n",
        "# 最適化の手法はSGDで。lossの減りに時間かかるけど、一旦はこれを使う。\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 各エポックの合計loss値を格納する\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "    all_loss = 0\n",
        "    for review, star in zip(traindata[\"review_body\"], traindata[\"stars\"]):\n",
        "        # モデルが持ってる勾配の情報をリセット\n",
        "        model.zero_grad()\n",
        "        # 文章を単語IDの系列に変換（modelに食わせられる形に変換）\n",
        "        try:\n",
        "            inputs = sentence2vec(review).to(device)\n",
        "        except KeyError:\n",
        "            continue\n",
        "        # 順伝播の結果を受け取る\n",
        "        out = model(inputs.view(len(inputs), 1, -1))\n",
        "        # 正解カテゴリをテンソル化\n",
        "        answer = category2tensor(star).to(device)\n",
        "        # 正解とのlossを計算\n",
        "        loss = loss_function(out, answer)\n",
        "        # 勾配をセット\n",
        "        loss.backward()\n",
        "        # 逆伝播でパラメータ更新\n",
        "        optimizer.step()\n",
        "        # lossを集計\n",
        "        all_loss += loss.item()\n",
        "    losses.append(all_loss)\n",
        "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
        "print(\"done.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 \t loss 5367.480199138938\n",
            "epoch 1 \t loss 4223.529006755956\n",
            "epoch 2 \t loss 3613.036225523696\n",
            "epoch 3 \t loss 2846.7030794272414\n",
            "epoch 4 \t loss 2353.902700705481\n",
            "epoch 5 \t loss 1858.614777554691\n",
            "epoch 6 \t loss 1444.4963462417363\n",
            "epoch 7 \t loss 1162.4205461412917\n",
            "epoch 8 \t loss 972.7492849509958\n",
            "epoch 9 \t loss 782.4842879778732\n",
            "epoch 10 \t loss 606.2658733303482\n",
            "epoch 11 \t loss 502.69802256610086\n",
            "epoch 12 \t loss 402.54682404890787\n",
            "epoch 13 \t loss 338.7433891646438\n",
            "epoch 14 \t loss 295.7265398152985\n",
            "epoch 15 \t loss 274.2294589365382\n",
            "epoch 16 \t loss 253.4102107794356\n",
            "epoch 17 \t loss 226.18296797293976\n",
            "epoch 18 \t loss 190.01480402146603\n",
            "epoch 19 \t loss 163.58054957603147\n",
            "epoch 20 \t loss 137.4106667027835\n",
            "epoch 21 \t loss 122.41954529701995\n",
            "epoch 22 \t loss 105.2809877166584\n",
            "epoch 23 \t loss 104.57771686189471\n",
            "epoch 24 \t loss 90.56952390678322\n",
            "epoch 25 \t loss 82.35541464102116\n",
            "epoch 26 \t loss 72.15078987398341\n",
            "epoch 27 \t loss 59.99905738915885\n",
            "epoch 28 \t loss 51.979576406583874\n",
            "epoch 29 \t loss 44.63139597249261\n",
            "epoch 30 \t loss 42.388587981675954\n",
            "epoch 31 \t loss 41.0600968372965\n",
            "epoch 32 \t loss 38.72533516431773\n",
            "epoch 33 \t loss 34.433035308029815\n",
            "epoch 34 \t loss 33.14318803458219\n",
            "epoch 35 \t loss 29.042538076311004\n",
            "epoch 36 \t loss 26.218554695001117\n",
            "epoch 37 \t loss 23.049601332457286\n",
            "epoch 38 \t loss 21.32136898057091\n",
            "epoch 39 \t loss 18.739779990000685\n",
            "epoch 40 \t loss 16.925879393259734\n",
            "epoch 41 \t loss 14.664693384632532\n",
            "epoch 42 \t loss 13.20155616136455\n",
            "epoch 43 \t loss 11.88940615490414\n",
            "epoch 44 \t loss 11.673253601765168\n",
            "epoch 45 \t loss 11.1799344307247\n",
            "epoch 46 \t loss 10.765584102272786\n",
            "epoch 47 \t loss 9.763449386856706\n",
            "epoch 48 \t loss 9.100768540408481\n",
            "epoch 49 \t loss 8.203888210552634\n",
            "epoch 50 \t loss 7.557569231847594\n",
            "epoch 51 \t loss 7.172515533702949\n",
            "epoch 52 \t loss 6.714526429607776\n",
            "epoch 53 \t loss 6.127828508721482\n",
            "epoch 54 \t loss 5.787449887265428\n",
            "epoch 55 \t loss 5.568291783894125\n",
            "epoch 56 \t loss 5.309917806511283\n",
            "epoch 57 \t loss 4.979614011341756\n",
            "epoch 58 \t loss 4.53130082840477\n",
            "epoch 59 \t loss 4.3217017828465885\n",
            "epoch 60 \t loss 4.065918256293628\n",
            "epoch 61 \t loss 3.8138560459180297\n",
            "epoch 62 \t loss 3.518829966476318\n",
            "epoch 63 \t loss 3.25542978262186\n",
            "epoch 64 \t loss 3.0782442356029414\n",
            "epoch 65 \t loss 2.8954038531270925\n",
            "epoch 66 \t loss 2.8406463001524287\n",
            "epoch 67 \t loss 2.779514233795343\n",
            "epoch 68 \t loss 2.777705157958767\n",
            "epoch 69 \t loss 2.711652667637214\n",
            "epoch 70 \t loss 2.7208240132905708\n",
            "epoch 71 \t loss 2.6699089378063547\n",
            "epoch 72 \t loss 2.63309697621807\n",
            "epoch 73 \t loss 2.581883894590238\n",
            "epoch 74 \t loss 2.4290694253097342\n",
            "epoch 75 \t loss 2.2369966447453358\n",
            "epoch 76 \t loss 2.0471188708448906\n",
            "epoch 77 \t loss 1.930906948359123\n",
            "epoch 78 \t loss 1.852638522845929\n",
            "epoch 79 \t loss 1.8120243183369276\n",
            "epoch 80 \t loss 1.7865996512599054\n",
            "epoch 81 \t loss 1.7447000470953533\n",
            "epoch 82 \t loss 1.6926138971595748\n",
            "epoch 83 \t loss 1.6548837684377915\n",
            "epoch 84 \t loss 1.5609190097361143\n",
            "epoch 85 \t loss 1.5075943478697447\n",
            "epoch 86 \t loss 1.4741728828367293\n",
            "epoch 87 \t loss 1.4942853509981724\n",
            "epoch 88 \t loss 1.5183169024990768\n",
            "epoch 89 \t loss 1.5383736301410131\n",
            "epoch 90 \t loss 1.5060671227069093\n",
            "epoch 91 \t loss 1.5341765984776004\n",
            "epoch 92 \t loss 1.438870967761268\n",
            "epoch 93 \t loss 1.4312621803489805\n",
            "epoch 94 \t loss 1.2373344974262075\n",
            "epoch 95 \t loss 1.1603910118665972\n",
            "epoch 96 \t loss 0.9888575467446259\n",
            "epoch 97 \t loss 0.9486017532228033\n",
            "epoch 98 \t loss 0.8324972701330395\n",
            "epoch 99 \t loss 0.820853891612078\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "F1OrN0w07AA0",
        "outputId": "799887b5-ab69-4769-9df0-b4b0a7aa9bd4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(losses)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe4e5518490>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0HAS8SmI5kR",
        "outputId": "8521ecad-1ed7-4edc-c73a-33ec081613e7"
      },
      "source": [
        "# テストデータの母数計算(1500)\n",
        "test_num = len(testdata)\n",
        "skip_num = 0\n",
        "# 正解の件数\n",
        "match = 0\n",
        "# 勾配自動計算OFF\n",
        "with torch.no_grad():\n",
        "    for review, star in zip(testdata[\"review_body\"], testdata[\"stars\"]):\n",
        "        # テストデータの予測\n",
        "        try:\n",
        "            inputs = sentence2vec(review).to(device)\n",
        "        except KeyError:\n",
        "            skip_num += 1\n",
        "            continue\n",
        "        out = model(inputs.view(len(inputs), 1, -1))\n",
        "\n",
        "        # outを四捨五入して一致数を数える\n",
        "        predict = torch.round(out).to(device)\n",
        "        if predict < 0:\n",
        "            predict = torch.tensor(0).to(device)\n",
        "        elif predict > 4:\n",
        "            predict = torch.tensor(4).to(device)\n",
        "\n",
        "        answer = category2tensor(star).to(device)\n",
        "        if predict == answer:\n",
        "            match += 1\n",
        "tested_num = test_num - skip_num\n",
        "print(f\"predict : {match / tested_num}, match: {match}, tested_num: {tested_num}\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict : 0.35329795299469297, match: 466, tested_num: 1319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE9J2zRLJId_"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}